'use strict'

// Attempt to download GitLab job artifact and failover to GitHub if unsuccessful.
// In GitLab Pages, the latest job status will be marked as unknown/failed if the repo has newer commit.
// The link to download the latest job artifact will also be unavailable when that happens,
// unless manually queried through API.
// Instead of using the API, I find it easier to failover to GitHub.
// ref: https://gitlab.com/gitlab-org/gitlab/-/issues/29257

import unzip from 'extract-zip'
import { basename, dirname, join } from 'node:path'
import { mkdir, readdir, rm } from 'node:fs/promises'
import { createWriteStream } from 'node:fs'
import { pipeline } from 'node:stream/promises'
import { fileURLToPath } from 'node:url'
import { Readable } from 'node:stream'

const __dirname = dirname(fileURLToPath(import.meta.url))
const envVar = process.env
const rootPath = join(__dirname, '..')
const tmpPath = join(rootPath, 'tmp')
const publicPath = join(rootPath, 'public')
const projects = [
  'urlhaus-filter',
  'phishing-filter',
  'tracking-filter',
  'vn-badsite-filter',
  'botnet-filter',
  // 'pup-filter'
]
const oisdFilters = {
  'https://abp.oisd.nl/basic/': 'oisd_abp_light.txt',
  'https://abp.oisd.nl/': 'oisd_abp.txt',
  'https://dbl.oisd.nl/basic/': 'oisd_dbl_light.txt',
  'https://dbl.oisd.nl/': 'oisd_dbl.txt',
  'https://dblw.oisd.nl/': 'oisd_dblw_light.txt',
  'https://dblw.oisd.nl/basic/': 'oisd_dblw.txt',
  'https://hosts.oisd.nl/basic/': 'oisd_hosts_light.txt',
  'https://hosts.oisd.nl/': 'oisd_hosts.txt',
  'https://dnsmasq.oisd.nl/basic/': 'oisd_dnsmasq_light.txt',
  'https://dnsmasq.oisd.nl/': 'oisd_dnsmasq.txt',
  'https://rpz.oisd.nl/basic/': 'oisd_rpz_light.txt',
  'https://rpz.oisd.nl/': 'oisd_rpz.txt',
}

const pipelineStatus = async (url) => {
  console.log(`Checking pipeline from "${url}"`)
  try {
    const svg = await (await fetch(url)).text()
    if (svg.includes('failed')) throw new Error('last gitlab pipeline failed')
  } catch ({ message }) {
    throw new Error(message)
  }
}

const dl = async (project) => {
  const filename = project + '.zip'
  const link = `https://gitlab.com/malware-filter/${project}/-/jobs/artifacts/main/download?job=pages`
  const zipPath = join(tmpPath, filename)
  const pipelineUrl = `https://gitlab.com/malware-filter/${project}/badges/main/pipeline.svg`
  let isMirror = false

  console.log(`Downloading ${filename} from "${link}"`)
  try {
    await pipeline(
      Readable.fromWeb((await fetch(link)).body),
      createWriteStream(zipPath)
    )
    await pipelineStatus(pipelineUrl)
  } catch ({ message }) {
    console.error(JSON.stringify({
      error: message,
      link,
      filename
    }))

    const mirrorLink = `https://nightly.link/curbengh/${project}/workflows/pages/main/public.zip`
    console.log(`Downloading ${filename} from "${mirrorLink}"`)
    isMirror = true

    try {
      await pipeline(
        Readable.fromWeb((await fetch(mirrorLink)).body),
        createWriteStream(zipPath)
      )
    } catch ({ message }) {
      throw new Error(JSON.stringify({
        error: message,
        link: mirrorLink,
        filename
      }))
    }
  }

  console.log(`Extracting ${basename(zipPath)}...`)
  if (isMirror === false) {
    await unzip(zipPath, { dir: rootPath })
  } else {
    await unzip(zipPath, { dir: publicPath })
  }
}

const oisdDl = async (link, filename) => {
  const txtPath = join(publicPath, filename)
  console.log(`Downloading ${filename} from "${link}"`)
  try {
    await pipeline(
      Readable.fromWeb((await fetch(link)).body),
      createWriteStream(txtPath)
    )
  } catch ({ message }) {
    console.error(JSON.stringify({
      error: message,
      link,
      filename
    }))
  }
}

const f = async () => {
  await mkdir(tmpPath, { recursive: true })
  await mkdir(publicPath, { recursive: true })
  await Promise.all(projects.map((project) => { return dl(project) }))

  const files = await readdir(publicPath)
  await Promise.all(files.map(async (file) => {
    // cf pages limits file size to 26.2MB
    // compressed (br/gz) files are excluded
    if (file.startsWith('phishing-filter') && file.endsWith('.rules')) {
      await rm(join(publicPath, file))
    }
  }))
}

const oisd = async () => {
  await mkdir(publicPath, { recursive: true })
  if (Object.hasOwn(envVar, 'CI_PROJECT_PATH') && envVar.CI_PROJECT_PATH === 'malware-filter/malware-filter') {
    await Promise.all(Object.entries(oisdFilters).map(([link, filename]) => { return oisdDl(link, filename) }))
  }
}

f()
oisd()
